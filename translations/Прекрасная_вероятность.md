# Прекрасная вероятность
Должны ли мы ожидать, что на определенном уровне рациональность будет простой? Должны ли мы надеяться и искать красоту в искусстве убеждения и выбора? 

Позвольте мне привести цитату покойного мастера Байесианства Джейнса (1990): 

«Два медика-исследователя используют одинаковую методику лечения независимо друг от друга в разных больницах. Ни один из них не фальсифицирует данные, однако один решил заранее, что из-за ограниченности ресурсов он остановится после лечения N=100 пациентов, сколько бы вылечившихся ни было. Другой поставил на кон свою репутацию и решил, что он не остановится, пока данные не покажут, что процент вылеченных больше 60%, сколько бы пациентов ни потребовалось. На деле, оба остановились на почти одинаковых данных: n=100 [пациентов], r=70 [вылеченных]. Должны ли мы сделать разные выводы из их экспериментов?» (по-видимому, две контрольные группы также дали равные результаты).

В соответствии со статистической процедурой старой школы — которой, я верю, все еще обучают сегодня — два исследователя выполнили разные эксперименты с разными условиями прекращения. Два эксперимента могли быть прекращены с разными данными и таким образом представлять разные тесты гипотезы, требуя различных методов статистического анализа. Поэтому весьма возможно, что первый эксперимент будет «статистически значимым», а второй нет. 

То, волнует ли вас это или нет, говорит о том, волнует ли вас теория вероятности и рациональность сама по себе. 

Статистики-небайесианцы могут пожимать плечами, говоря «ну, не все статистические инструменты имеют одни и те же сильные и слабые стороны, вы же знаете, молоток не похож на отвертку, и если вы применяете разные статистические инструменты, вы можете получить разные результаты, в зависимости от того, обрабатываем мы данные вычисляя линейную регрессию или тренируя нейронную сеть. Вы должны использовать правильный инструмент для каждого отдельного случая. Жизнь запутанна».

И тогда Байесианцы отвечают: «Извините? Очевидное влияние фиксированного экспериментального метода, продуцирующего одинаковые данные, зависит от частных мыслей исследователя? И вы еще умудряетесь обвинять нас в «чрезмерной субъективности?»

Если Природа устроена одним образом, то так же данные, пришедшие путем, который мы видели, должны представлять одно явление. Если Природа устроена другим образом, то данные должны отражать что-то еще. Однако состояние Природы, которое отражено в данных, никак не зависит от намерений исследователя. Так что каковы бы не были наши гипотезы о Природе, отношение правдоподобия остается одним и тем же, и доказательное влияние то же самое, и апостериорное убеждение должно быть тем же самым между двумя экспериментами. По меньшей мере один из двух методов старой школы должен учитывать не всю информацию, или просто вычисляться с ошибкой, чтобы два метода дали разные ответы. 

Древняя война между байесианцами и сторонниками частотного подхода тянется уже десятилетия, и я не собираюсь рассматривать всю эту историю в данном посте. 

Но один из центральных конфликтов в том, что байесианцы ожидают, что теория вероятности будет... как же это сказать? Стройной? Ясной? Самосогласующейся? 

Как говорит Джейнс, теоремы байесианской вероятности — это просто теоремы когерентной системы доказательств. Не имеет значения, как вы обрабатываете данные в этом случае, результаты байесианской теории вероятности должны быть всегда одни и те же — каждая теорема совместима с любой другой теоремой. 

Если вы хотите узнать сумму 10+10, вы можете вычислять это как (2 × 5) + (7 + 3) или как (2 × (4 + 6)) или использовать любой другой метод который вам нравится, но результат должен быть всегда один и то же, в данном случае 20. Если же в одном случае получается 20, а в другом 19, тогда вы можете заключить, что вы сделали что-то неправильно по крайней мере в одном из вычислений. (В математике недопустимой операцией обычно является деление на ноль; в теории вероятности это обычно бесконечность, что нельзя использовать как предел конечного процесса.) 

Если вы принимаете результат 19=20, внимательно рассмотрите ошибку, которую вы сделали, поскольку не может быть, чтобы вы могли математически обмануть себя. Если бы кто-то преуспел в получении реального противоречия в байесианской теории вероятности — такого, скажем, как два различных доказательных воздействия от одного и того же экспериментального метода, принимающего на вход одинаковые результаты, тогда вся конструкция была бы дымом. Вместе с теорией множеств, поскольку я считаю, что теория множеств обеспечивает модель для теории вероятности. 

Математическая! Вот слово которое я искал. Байесианцы ожидают что теория вероятности будет математической. Вот почему мы заинтересованы в теореме Кокса и ее расширениях, показывающих, что любое представление неопределенности, которое подчиняется определенным ограничениям, должно отображаться посредством теории вероятности. Когерентная математика это великолепно, но уникальная математика еще лучше. 

И еще, должна ли рациональность быть "математична"? Не является предопределенным то, что вероятность должна быть красивой. Реальный мир сложен — так, возможно, вам нужно будет сложное мышление, чтобы с этим справиться? Возможно, что статистики-небайесианцы с их большой коллекцией специальных методов и обоснований более компетентны, поскольку у них строго больший инструментарий. Хорошо, когда проблемы ясны, но обычно это не так, и вам придется с этим жить. 

В конце концов, хорошо известно, что вы не можете использовать байесовские методы на множестве проблем из-за того, что байесовские вычисления сложны для подсчетов. Так почему бы не позволить цвести многим цветам? Почему бы не иметь больше одного инструмента в вашем наборе? 

Это фундаментальное различие в сознании. Статистики старой школы думают в терминах инструментов и трюков, применяемых для определенных проблем. Байесианцы, по крайней мере этот байесианец, хотя я не думаю, что говорю только за себя, — мы думаем в терминах законов. 

Поиск законов — это не то же самое, что поиск особенно чистых и красивых инструментов. Второй закон термодинамики — это не одно и то же, что и чистый и красивый холодильник. 

Цикл Карно это идеальный двигатель — на самом деле идеальный. Нет двигателя, который бы питался от двух накопителей тепла и был бы эффективней, чем двигатель Карно. Как следствие, все термодинамически обратимые двигатели, которые функционируют между одинаковыми накопителями тепла, имеют одинаковую эффективность. 

Но, конечно, вы не можете использовать двигатель Карно для питания реальной машины. Двигатель машины имеет такое же сходство с двигателем Карно, что и шины автомобиля с идеальными катящимися цилиндрами. 

Тогда ясно, что двигатель Карно — бесполезный инструмент для постройки настоящей машины. Второй закон термодинамики, очевидно, неприменим здесь. Чересчур сложно сделать двигатель, который будет отвечать таким условиям, в реальности. Просто игнорируйте термодинамику — используйте все, что работает. 

Это определенный род путаницы, который, как я думаю, управляет теми, кто все еще цепляется за старые методы. 

Нет, вы не можете всегда делать точные байесовские вычисления для проблемы. Иногда вам надо искать аппроксимацию; на самом деле, часто. Это не значит, что теорию вероятности нужно прекратить применять, так же как ваша неспособность вычислить аэродинамику самолета из атомных взаимодействий не означает, что самолет не сделан из атомов. Какую бы аппроксимацию вы не использовали, она будет работать, если является аппроксимацией идеального байесовского вычисления — и не будет работать в любом другом случае. 

Доказательства когерентности и уникальности байесианства отметают оба пути. Также, как любой расчет, который подчиняется аксиомам когерентности Кокса (или любой из его переформулировок или обобщений), должен отображаться в вероятностях, любой не байесовский расчет должен провалить какой-либо из тестов на когерентность. Что, в свою очередь, приводит к наказаниям, таким как голландское бронирование (прием комбинаций ставок, которые приводят к точным убыткам или отказу от комбинаций, которые дают точные выгоды). 

Вы можете быть не способны вычислить оптимальный ответ. Но любая аппроксимация которую вы используете, с ее достоинствами и недостатками, должна быть объяснима с позиции байесовской теории вероятности. Вы можете не знать объяснения: но это не значит, что его не существует. 

Так вы хотите использовать линейную регрессию вместо байесовских обновлений? Но посмотрите на структуру, лежащую в основе линейной регрессии, и вы увидите, что она выбирает лучшую точку с позиции оценки, данной гауссовской функцией правдоподобия, и ставит исходное над параметрами. 

Вы хотите использовать регуляризованную линейную регрессию, потому что она работает на практике лучше? Ну, она соответствует (говорит байесианец) тому, чтобы ставить гауссову априорную информацию над весами. 

Иногда вы не можете использовать байесовские методы так, как это описано в литературе; на самом деле это бывает довольно часто. Но когда вы можете использовать точное байесовское вычисление, которое использует каждый кусочек доступной вам информации, делайте это. Вы никогда не найдете статистический метод, который даст вам лучший ответ. Вы можете найти простую аппроксимацию, которая работает отлично почти все время, и так будет проще, но не точнее. Не будет, пока другие методы используют знания, возможно, в форме неявной априорной информации, что не позволяется при байесовских вычислениях; и тогда, когда вы применяете априорную информацию для байесовского вычисления, оно будет либо равно по результатам, либо будет лучше. 

Когда вы используете специальный статистический инструмент старой школы с каким-либо (часто достаточно интересным) обоснованием, вы никогда не знаете, если у кого-то завтра появиться более продвинутый инструмент. Но когда вы напрямую можете использовать вычисление, которое отражает байесовский закон, вы делаете что-то наподобие помещения двигателя Карно в свою машину. Это, как говорится, по-байесовски оптимально. 

Мне кажется, что те, кто пользуется множеством инструментов, смотрят на последовательность кубов {1, 8, 27, 64, 125, ...}, указывают на разности {7, 19, 37, 61, ...} и говорят «смотрите, жизнь не всегда проста — вам нужно адаптироваться к обстоятельствам». И байесианцы, которые указывают на лежащий в основе стабильный уровень {6, 6, 6, 6, 6, ...}. И критики говорят: «Что за чушь вы несете? Это 7, 19, 37, а не 6, 6, 6. Вы упрощаете проблему, вы слишком привязаны к простоте».

Бесполезно быть простым на поверхностном уровне. Вы должны погрузиться глубже, чтобы найти стабильность. 

Мыслите законами, а не инструментами. Необходимость вычислять приближения (аппроксимации) к закону не меняет закон. Самолеты по-прежнему состоят из атомов, они не станут исключением только из-за аэродинамических вычислений. Аппроксимация существует на карте, не на территории. Вы можете знать второй закон термодинамики и все еще пробовать себя как инженера, строя несовершенный двигатель машины. Второй закон не станет неприменим; ваше знание этого закона и цикла Карно помогает вам приблизиться к наибольшей эффективности, которую вы только можете достигнуть. 

Мы не очаровываемся байесовскими методами только потому, что они красивы. Красота всего лишь побочный эффект. Теоремы Байеса изящны, когерентны, оптимальны и доказуемо однозначны потому, что они относятся к законам. 

Приложение: Cyan отсылает нас к главе 37 книги о статистике Маккая, где данная проблема рассматривается более подробно. 

Jaynes, E. T. (1990.) Probability Theory as Logic. In: P. F. Fougere (Ed.), Maximum Entropy and Bayesian Methods. Kluwer Academic Publishers. 

MacKay, D. (2003.) Information Theory, Inference, and Learning Algorithms. Cambridge: Cambridge University Press.