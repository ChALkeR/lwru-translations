# Лжепричинность
Флогистон — это ответ Европы XVIII века на первоэлемент огня, введённый греческими алхимиками. Зажги древесину и позволь ей сгореть. Что представляет из себя эта яркая оранжевая штука? Почему древесина превратилась в пепел? На оба эти вопроса химики XVIII века отвечали — «флогистон». 

…и больше ничего. Это всё, в этом и заключался их ответ: «флогистон». 

Флогистон покидал горящие вещества как видимое пламя. В результате горящие вещества теряли свой флогистон и становились пеплом, своим «истинным материалом». Огонь, помещённый в герметичный сосуд, быстро гас потому, что воздух насыщался флогистоном и больше не мог его вместить. Уголь почти не оставлял никакого пепла, потому что он почти полностью состоял из флогистона. 

Разумеется, никто не использовал теорию флогистона для того, чтобы *предсказать* результат химического превращения. Алхимик сначала смотрел на результат, а затем при помощи флогистона *объяснял* его. Не было и намёка на то, чтобы флогистонщики предсказали прекращение горения в замкнутом сосуде; они, скорее, зажгли огонь в сосуде, увидели его угасание и затем сказали: «Должно быть, воздух насытился флогистоном». Теорию флогистона нельзя применить для того, чтобы выяснить, [чего ты точно не сможешь увидеть][1]. Она может объяснить всё. 

Наука ещё только начинала выходить на сцену. Очень долго никто не осознавал, что в этой теории что-то не так. 

Встретив [лжеобъяснение][2], очень легко не ощутить его фальшивость: потому они и опасны. 

Современные специалисты предполагают, что люди думают о причино-следственных связях, используя нечто вроде направленных ациклических графов или байесовских сетей. Поскольку шел дождь, тротуар мокрый; поскольку тротуар мокрый, он скользкий: 

[Дождь] -> [Тротуар мокрый] -> [Тротуар скользкий] 

Из этого можно вывести (а, имея байесовскую сеть, можно даже точно вычислить эту вероятность), что, если тротуар скользкий, то, вероятно, шёл дождь. Однако, если уже известно о мокрости тротуара, то сообщение о его скользкости не несёт в себе никакой новой информации о дожде. 

Почему огонь горячий и яркий? 

[«Флогистон»] -> [Огонь горячий и яркий] 

Это *выглядит* как объяснение. И в мозгу эта информация *хранится* в том же формате и под тем же расширением, что и «настоящие» объяснения. Но человеческий разум неспособен автоматически определить, что стрелка, соединяющая гипотезу с её возможными следствиями, никак не ограничивает пути, которыми могут проявляться эти следствия. [Эффект знания задним числом][3] делает ситуацию ещё хуже: люди могут считать, что гипотеза действительно [ограничивает][4] происходящее, хотя на самом деле гипотеза [подогнана][5] под происходящее постфактум. 

Современная трактовка вероятностных рассуждений о причинности может точно описать, в чём именно состояла ошибка флогистонщиков. Байесовские сети были разработаны для того, чтобы, кроме всего прочего, не учитывать свидетельства дважды в том случае, когда логический вывод между причиной и следствием возможен в обе стороны. Например, я добыл кусочек ненадёжной информации о том, что тротуар мокрый. Это заставляет меня подумать: «возможно, идёт дождь». Но если идёт дождь, то утверждение «тротуар мокрый» стало более правдоподобным, так? То же самое ведь касается и скользкости тротуара, верно? Но если тротуар скользкий, то он, скорее всего, мокрый — и тогда нужно опять повысить вероятность того, что идёт дождь. 

Джуда Перл приводит в качестве метафоры алгоритм подсчёта солдат в линии. Представьте, что вы стоите в линии и видите рядом только двух солдат: одного спереди и одного сзади. Всего трое солдат. Вы спрашиваете своего соседа: «Сколько солдат ты видишь?» Он оглядывается и говорит: «Троих». Получается, всего солдат шесть. Очевидно, что так решать эту задачу *не* стоит. 

Умнее будет спросить у стоящего впереди солдата: «Сколько солдат перед тобой?», и у стоящего позади: «Сколько солдат за тобой?». Сообщение с вопросом «сколько солдат перед тобой?» можно передать дальше без особых затруднений. Если я стою первым, то я передам назад «1 солдат впереди». Человек, стоящий прямо за мной, получит сообщение «1 солдат впереди» и скажет второму своему соседу «2 солдата впереди». В это же время кто-то получает сообщение «N солдат позади» и передаёт стоящему впереди солдату сообщение «N+1 солдат позади». Сколько же всего солдат? Сложите оба полученных числа и добавьте единицу для себя — это и есть общее число солдат в линии. 

Ключевая идея состоит в том, что каждый солдат должен *отдельно* отслеживать эти два сообщения, прямое и обратное, и сложить их вместе только в конце. Нельзя добавлять солдат из обратного сообщения, которое ты получил, в прямое сообщение, которое ты передашь дальше. Разумеется, сообщение с общим числом солдат никогда не появляется в этой цепочке: никто не произносит этого числа вслух. 

Аналогичный принцип применяется в строгих вероятностных рассуждениях о причинности. Получение из *не связанного* с мокрым тротуаром источника каких-либо свидетельств о дожде создаст прямое сообщение от узла [дождь] к узлу [мокрый тротуар], и тем самым усилит ожидание увидеть мокрый тротуар. Наблюдение мокрого тротуара создаст обратное сообщение, идущее к убеждению о дожде, а затем это сообщение распространится от узла [дождь] до всех его соседей, *кроме* узла [мокрый тротуар]. Каждый кусочек свидетельства учитывается ровно единожды; корректировки никогда не застревают между узлами, скача туда и обратно. Точный алгоритм можно найти в классической книге «Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference» Джуды Перла. 

Так что же было неправильно в теории флогистона? Когда мы наблюдаем, что огонь горячий, узел [огонь] посылает обратное сообщение со свидетельством узлу [флогистон], вынуждая нас обновить убеждения о флогистоне. Но тогда мы не можем считать это успешным предсказанием теории флогистона. Сообщение должно идти в единственном направлении, не отражаясь назад. 

Увы, для обновления сетей убеждений люди используют не строгий алгоритм, а его грубое приближение. Мы изучаем родительские узлы, наблюдая за дочерними узлами, и предсказываем поведение дочерних узлов, используя убеждения о родительских узлах. Но ящик с документацией по прямым сообщениям не отделён от ящика с документацией по обратным сообщениям толстой непроницаемой стеной. Мы просто помним: «флогистон горячий, *и из-за этого* огонь тоже горячий». Всё это выглядит так, будто теория флогистона предсказывает «горячесть» огня. Или, что ещё хуже, нам кажется: «флогистон *делает* огонь горячим». 

Лишь после того, как кто-нибудь заметит полное отсутствие предсказаний заранее, не ограничивающий ожиданий причинно-следственный узел получит ярлык «фальшивка». До этого момента он не будет отличаться от остальных узлов в сети убеждений. Утверждение «флогистон делает огонь горячим» ощущается фактом точно так же, как и все остальные известные тебе факты. 

Правильно спроектированный ИИ заметит проблему мгновенно. Для этого не понадобится какой-нибудь особенной заплатки, нужен всего лишь правильный учёт происходящего в сети убеждений (к сожалению, в отличие от правильно спроектированных ИИ, люди не способны переписывать свой исходный код, чтобы исправить найденные ошибки) 

Рассуждения об «[эффекте знания задним числом][7]» — это просто способ не привлекая технических терминов рассказать о том, что люди не разделяют прямые и обратные сообщения, из-за чего прямые сообщения могут загрязняться обратными. 

Люди, пошедшие по пути флогистона, не намеревались стать дураками. Ни один учёный не желает застрять в тупике. Не скрываются ли лжеобъяснения в недрах *твоего* разума? Если они там есть, то к ним определённо не приклеен ярлык «лжеобъяснение», и поэтому поиска по ключевому слову «фальшивка» явно недостаточно для того, чтобы их обнаружить. 

Проверить, насколько хорошо теория «предсказывает» уже известные тебе факты, также недостаточно: [эффект знания задним числом][7] обесценит все усилия. Предсказывать нужно на завтра, а не на вчера. Лишь так можно быть уверенным в том, что захламлённый человеческий разум действительно посылает чистое прямое сообщение.

 [1]: /w/%D0%A1%D0%B8%D0%BB%D0%B0_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D0%B8%D1%81%D1%82%D0%B0 "Сила рационалиста"
 [2]: /w/%D0%9B%D0%B6%D0%B5%D0%BE%D0%B1%D1%8A%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F "Лжеобъяснения"
 [3]: /w/%D0%9A%D0%BE%D0%B3%D0%BD%D0%B8%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%B5_%D0%B8%D1%81%D0%BA%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F#simple-table-of-contents-3 "Знание задним числом"
 [4]: /w/%D0%A3%D0%B1%D0%B5%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B4%D0%BE%D0%BB%D0%B6%D0%BD%D1%8B_%D0%BE%D0%BA%D1%83%D0%BF%D0%B0%D1%82%D1%8C%D1%81%D1%8F "Убеждения должны окупаться"
 [5]: /w/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D1%81%D0%BE%D1%85%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%B5%D0%BC%D1%8B%D1%85_%D1%81%D0%B2%D0%B8%D0%B4%D0%B5%D1%82%D0%B5%D0%BB%D1%8C%D1%81%D1%82%D0%B2 "Закон сохранения ожидаемых свидетельств"
 [7]: /w/%D0%97%D0%BD%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B7%D0%B0%D0%B4%D0%BD%D0%B8%D0%BC_%D1%87%D0%B8%D1%81%D0%BB%D0%BE%D0%BC_%D0%BE%D0%B1%D0%B5%D1%81%D1%86%D0%B5%D0%BD%D0%B8%D0%B2%D0%B0%D0%B5%D1%82_%D0%BD%D0%B0%D1%83%D0%BA%D1%83 "Знание задним числом обесценивает науку"